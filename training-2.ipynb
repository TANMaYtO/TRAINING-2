{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":12946503,"sourceType":"datasetVersion","datasetId":8192880}],"dockerImageVersionId":31089,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-04T05:44:38.285054Z","iopub.execute_input":"2025-09-04T05:44:38.285483Z","iopub.status.idle":"2025-09-04T05:44:38.754143Z","shell.execute_reply.started":"2025-09-04T05:44:38.285377Z","shell.execute_reply":"2025-09-04T05:44:38.752764Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/training2-titanic-data/titanic.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"## DAY-1\ndata = []\nn= int(input('number of employees: '))\nfor i in range(n):\n    print(f\"\\nEnter details for employee {i+1}:\")\n    name = input(\"Name: \")\n    age = int(input(\"Age: \"))\n    department = input(\"Department: \")\n    salary = int(input(\"Salary: \"))\n    \n    # append to list as dictionary\n    data.append({\n        \"name\": name,\n        \"age\": age,\n        \"department\": department,\n        \"salary\": salary\n    })           \n\ndf = pd.DataFrame(data)\n\ndf.head(3)\n\ndf[['name', 'salary']]\n\navg_sal = df['salary'].mean()\navg_sal\n\nmax_sal = df['salary'].max()\nprint(df['name'][df['salary'] == max_sal])\n\nnp.std(df['salary'])\n\nage = np.array(df['age'])\ndouble = age*2\ndouble","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:35:08.142764Z","iopub.execute_input":"2025-09-03T05:35:08.143283Z","iopub.status.idle":"2025-09-03T05:35:18.626469Z","shell.execute_reply.started":"2025-09-03T05:35:08.143260Z","shell.execute_reply":"2025-09-03T05:35:18.624717Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# DAY-3\ndf = pd.read_csv('/kaggle/input/training2-titanic-data/titanic.csv')\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:31.084428Z","iopub.execute_input":"2025-09-03T05:36:31.084791Z","iopub.status.idle":"2025-09-03T05:36:31.103607Z","shell.execute_reply.started":"2025-09-03T05:36:31.084766Z","shell.execute_reply":"2025-09-03T05:36:31.102844Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:33.243345Z","iopub.execute_input":"2025-09-03T05:36:33.243617Z","iopub.status.idle":"2025-09-03T05:36:33.250354Z","shell.execute_reply.started":"2025-09-03T05:36:33.243598Z","shell.execute_reply":"2025-09-03T05:36:33.249678Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Age'] = df['Age'].fillna(df['Age'].mean())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:33.413915Z","iopub.execute_input":"2025-09-03T05:36:33.414130Z","iopub.status.idle":"2025-09-03T05:36:33.419156Z","shell.execute_reply.started":"2025-09-03T05:36:33.414115Z","shell.execute_reply":"2025-09-03T05:36:33.418268Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:36.523169Z","iopub.execute_input":"2025-09-03T05:36:36.523441Z","iopub.status.idle":"2025-09-03T05:36:36.530360Z","shell.execute_reply.started":"2025-09-03T05:36:36.523420Z","shell.execute_reply":"2025-09-03T05:36:36.529562Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.drop(columns=['PassengerId', 'Cabin', 'Name', 'Ticket'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:36.655644Z","iopub.execute_input":"2025-09-03T05:36:36.656192Z","iopub.status.idle":"2025-09-03T05:36:36.660212Z","shell.execute_reply.started":"2025-09-03T05:36:36.656175Z","shell.execute_reply":"2025-09-03T05:36:36.659452Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:38.493298Z","iopub.execute_input":"2025-09-03T05:36:38.493569Z","iopub.status.idle":"2025-09-03T05:36:38.499317Z","shell.execute_reply.started":"2025-09-03T05:36:38.493548Z","shell.execute_reply":"2025-09-03T05:36:38.498611Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:38.717796Z","iopub.execute_input":"2025-09-03T05:36:38.718033Z","iopub.status.idle":"2025-09-03T05:36:38.728527Z","shell.execute_reply.started":"2025-09-03T05:36:38.718018Z","shell.execute_reply":"2025-09-03T05:36:38.727862Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.isnull().sum().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:43.957069Z","iopub.execute_input":"2025-09-03T05:36:43.957614Z","iopub.status.idle":"2025-09-03T05:36:43.962993Z","shell.execute_reply.started":"2025-09-03T05:36:43.957587Z","shell.execute_reply":"2025-09-03T05:36:43.962379Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\n# Encode Sex\ndf['Sex'] = LabelEncoder().fit_transform(df['Sex'])\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:45.840201Z","iopub.execute_input":"2025-09-03T05:36:45.840547Z","iopub.status.idle":"2025-09-03T05:36:45.853738Z","shell.execute_reply.started":"2025-09-03T05:36:45.840521Z","shell.execute_reply":"2025-09-03T05:36:45.852911Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Embarked'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:45.974892Z","iopub.execute_input":"2025-09-03T05:36:45.975135Z","iopub.status.idle":"2025-09-03T05:36:45.981799Z","shell.execute_reply.started":"2025-09-03T05:36:45.975118Z","shell.execute_reply":"2025-09-03T05:36:45.981094Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:46.113788Z","iopub.execute_input":"2025-09-03T05:36:46.113989Z","iopub.status.idle":"2025-09-03T05:36:46.122531Z","shell.execute_reply.started":"2025-09-03T05:36:46.113974Z","shell.execute_reply":"2025-09-03T05:36:46.121706Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:46.253822Z","iopub.execute_input":"2025-09-03T05:36:46.253999Z","iopub.status.idle":"2025-09-03T05:36:46.267040Z","shell.execute_reply.started":"2025-09-03T05:36:46.253986Z","shell.execute_reply":"2025-09-03T05:36:46.266443Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['Embarked_Q'] = df['Embarked_Q'].astype(int)\ndf['Embarked_S'] = df['Embarked_S'].astype(int)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:49.102142Z","iopub.execute_input":"2025-09-03T05:36:49.102430Z","iopub.status.idle":"2025-09-03T05:36:49.107256Z","shell.execute_reply.started":"2025-09-03T05:36:49.102410Z","shell.execute_reply":"2025-09-03T05:36:49.106572Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:49.250851Z","iopub.execute_input":"2025-09-03T05:36:49.251040Z","iopub.status.idle":"2025-09-03T05:36:49.263755Z","shell.execute_reply.started":"2025-09-03T05:36:49.251027Z","shell.execute_reply":"2025-09-03T05:36:49.262998Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = df.drop('Survived', axis=1)\ny = df['Survived']\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:49.404096Z","iopub.execute_input":"2025-09-03T05:36:49.404513Z","iopub.status.idle":"2025-09-03T05:36:49.574067Z","shell.execute_reply.started":"2025-09-03T05:36:49.404496Z","shell.execute_reply":"2025-09-03T05:36:49.573141Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\n# Define models in a dictionary\nmodel = RandomForestClassifier(n_estimators=200,random_state = 42)\n# Loop through models\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)    \nacc = accuracy_score(y_test, y_pred)\nprint(f\" Accuracy: {acc:.4f}\")\nprint(classification_report(y_test, y_pred))\nprint(\"-\" * 50)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:36:52.972191Z","iopub.execute_input":"2025-09-03T05:36:52.972478Z","iopub.status.idle":"2025-09-03T05:37:00.320641Z","shell.execute_reply.started":"2025-09-03T05:36:52.972458Z","shell.execute_reply":"2025-09-03T05:37:00.319793Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf[['Age', 'Fare']] = scaler.fit_transform(df[['Age', 'Fare']])\ndf","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:37:00.321984Z","iopub.execute_input":"2025-09-03T05:37:00.322960Z","iopub.status.idle":"2025-09-03T05:37:00.337039Z","shell.execute_reply.started":"2025-09-03T05:37:00.322937Z","shell.execute_reply":"2025-09-03T05:37:00.336306Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import TensorDataset, DataLoader\n\nX_tensor = torch.tensor(X.values, dtype=torch.float32)\ny_tensor = torch.tensor(y.values, dtype=torch.float32).view(-1, 1)\n\nX_train_t, X_test_t, y_train_t, y_test_t = train_test_split(X_tensor, y_tensor, test_size=0.2, random_state=42, stratify=y)\n\ntrain_dataset = TensorDataset(X_train_t, y_train_t)\ntest_dataset = TensorDataset(X_test_t, y_test_t)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\nclass titanicNN(nn.Module):\n    def __init__(self, inp):\n        super(titanicNN, self).__init__()\n        self.fc1 = nn.Linear(inp, 64)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Linear(64,128)\n        self.relu2 = nn.ReLU()\n        self.fc3 = nn.Linear(128, 1)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        x = self.relu1(self.fc1(x))\n        x = self.relu2(self.fc2(x))\n        x = self.sigmoid(self.fc3(x))\n        return x\n\nmodel = titanicNN(X.shape[1])\ncriterion = nn.BCELoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\nepochs = 1000\nfor EPOCH in range(epochs):\n    model.train()\n    for x_batch , y_batch in train_loader:\n        optimizer.zero_grad()\n        y_pred = model(x_batch)\n        loss = criterion(y_pred, y_batch)\n        loss.backward()\n        optimizer.step()\n\n    if (EPOCH+1)%10 == 0:\n        print(f\"Epoch {EPOCH+1}/{epochs}, Loss: {loss.item():.4f}\")\n\nmodel.eval()\nwith torch.no_grad():\n    y_pred_probs = model(X_test_t)\n    y_pred_labels = (y_pred_probs > 0.5).int()\n    acc = (y_pred_labels.eq(y_test_t.int()).sum().item()) / y_test_t.shape[0]\n    print(f\"Test Accuracy: {acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-03T05:38:56.217891Z","iopub.execute_input":"2025-09-03T05:38:56.218642Z","iopub.status.idle":"2025-09-03T05:39:35.668895Z","shell.execute_reply.started":"2025-09-03T05:38:56.218620Z","shell.execute_reply":"2025-09-03T05:39:35.668054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#### DAY- 4\nimport matplotlib.pyplot as plt\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrices import accuracy_score, f1_score, classification_report, confusion_matrix, roc_auc_score, roc_curve\ndef run(show_plot =True, verbose=True, random_state=69):\n    data= load_breast_cancer()\n    x,y= data.data, data.target\n\n    x_train, x_test, y_train, y_test = train_test_split(x,y,test_size = 0.2, random_state= random_state, stratify=y)\n    scaler= StandardScaler()\n    x_train= scaler.fit_transform(x_train)\n    x_test= scaler.fit_transform(x_test)\n    model = Logistic_Regresion(max_iter= 1000, solver= 'lbfgs', C= 1.0,random_state= random_state)\n    model.fit(x_train, y_train)\n    y_preds = model.predict(x_test)\n    \n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}